# 自我介绍

​		面试官你好，我叫曾博佳，毕业于北京师范大学珠海分校软件工程专业。开发技能上主要以Java语言为主，有扎实的Java基础和良好的编码风格，熟悉并发编程、JVM及锁知识，开发模式上熟悉以SpringBoot、SpringCloud为主的Web开发模式，但是最近有人了解到Go语言，也有意愿学习和转语言。目前的工作经历主要有两段，第一是做国际航运生命周期编排系统开发，特点是采用敏捷开发、微服务开发，采用K8S服务网格做微服务容器编排和部署。第二是在一家交通行业公司做智慧服务区的开发，它的特点主要是物联网、基础设备状态采集、微服务开发。最后做是简单的自我评价，我是一个比较上进，有较好的自我驱动力及自律能力，有机会的话希望能够进入到公司，跟优秀的人一起干有挑战性的事。



# 如何编写简历

- https://juejin.cn/post/6844904034218803214#heading-6



# 面试记录



CVTE一轮面试：

1. JVM
   1. 旧系统的OOM？OOM如何做检测和检查？
   2. 垃圾回收器
      1. 垃圾回收器有哪些？G1和CMS的区别？回收流程是什么？适合在什么场景？
      2. 新生代老年代的垃圾回收策略
   3. 标记-整理和标记-清除的区别？
   4. 做过哪些JVM上的优化？
   5. 如何检查线程数量，可以通过哪些方式去检查？JDK自带哪些工具？

2. 项目
   1. 旧系统为什么要进行拆分？
      1. 出现OOM？哪些OOM？内存泄露？线程创建过多？
      2. 线上部署了几个实例？
      3. 服务耦合，相互影响，版本控制困难。
   2. 微服务监控怎么做的？如何评估服务需要扩容？如何及时发现系统异常情况？
   3. 难点是什么？如何解决的？
   4. 拆分成多少个服务？微服务拆分时间多长？
   5. 数据库也是做了拆分吗？按数据表做垂直拆分？保证数据一致性（分布式事务）
   6. 单表数据量是多大？
   7. 采用了什么消息队列？为什么要用消息队列做服务通信而不用spring cloud？
   8. 项目采用了DDD，在微服务中DDD是如何分层的？
   9. 自己学习了什么知识？应用到项目了吗？
      1. 分布式事务
      2. 分布式ID
      3. redis bitmap
      4. 幂等性处理、有序性处理、可靠性处理
      5. netty nio采集
3. MySQL（回答的还可以）
   1. 如何进行优化？
   2. 索引结构有哪些？
   3. 有做分库分表吗？
   4. MySQL锁有哪些？间隙锁的作用是什么？（隔离级别：可重复读，解决幻读）
   5. 需要重点了解：死锁及解决思路



# 面试准备



## 计算机网络



### 状态码

- https://juejin.cn/post/7104117388676694046





## 算法



### 排序算法



#### 快速排序（普通 + 双指针）

> 不稳定算法
>
> 算法思想：分而治之（分治思想）
>
> 时间复杂度：
>
> - 最坏：O(n ^ 2)，数组基本有序并取最左边的作为pivot
> - 最好：O(nlog(n))，每次都能平均分割
> - 平均：O(nlog(n))
>
> 空间复杂度：
>
> - 最好：O(logn)：pivot为中间值，树平衡
> - 最坏：O(n)：数组基本有序，取第一个数作为pivot会导致生成树不平衡，数高度=数组长度
> - 平均：O(logn)

```
public int[] sortArray(int[] nums) {

    quickSort(nums, 0, nums.length - 1);

    return nums;
}

public void quickSort(int[] nums, int left, int right){
    if(left >= right){
        return;
    }

    int pIndex = partition(nums, left, right);
    quickSort(nums, left, pIndex - 1);
    quickSort(nums, pIndex + 1, right);
}

// 普通快排
private int partition1(int[] nums, int left, int right){

    int pivot = nums[left];
    int lt = left;

    for(int i = left + 1;i <= right;i ++){
        if(nums[i] <= pivot){
            lt ++;
            swap(nums, i, lt);
        }
    }
    swap(nums, left, lt);

    return lt;
}

// 双指针快排
private int partition2(int[] nums, int left, int right){

    int pivot = nums[left];
    int lt = left;
    int gt = right;

    while(lt < gt){
        while(lt < gt && nums[gt] >= pivot){
            gt --;
        }

        while(lt < gt && nums[lt] <= pivot){
            lt ++;
        }

        swap(nums, lt, gt);
    }
    swap(nums, left, lt);

    return lt;
}

private void swap(int[] nums, int left,int right){
    int tmp = nums[left];
    nums[left] = nums[right];
    nums[right] = tmp;
}
```



#### 堆排序

>不稳定算法
>
>时间复杂度：
>
>- 平均：O(nlogn)
>- 最坏：O(nlogn)
>
>空间复杂度：
>
>- O(1)

```
public int[] sortArray(int[] nums) {
    
    // 构建大根堆，堆顶为最大值
    int len = nums.length - 1;
    for(int i = len / 2;i >= 0;i --){
        adjustHeap(nums, i, len);
    }
	
	// 替换堆顶和数组尾，再次调整大根堆，重复提取当前堆的最大值即可完成排序
    for(int i = len;i >=0 ;i --){
        swap(nums, 0, i);
        adjustHeap(nums, 0, i - 1);
    }

    return nums;
}

// k为起始节点
private void adjustHeap(int[] nums, int k, int end){

    while(2 * k + 1 <= end){
        int j = 2 * k + 1;
        if(j + 1 <= end && nums[j + 1] >= nums[j]){
            j ++;
        }
        if(nums[j] > nums[k]){
        	// 由于发生了替换，所以被替换的子节点需要调整
            swap(nums, j, k);
            k = j;
        }else {
        	// 当前节点已经为所在堆最大值
            break;
        }
    }
}

private void swap(int[] nums, int left, int right){
    int tmp = nums[left];
    nums[left] = nums[right];
    nums[right] = tmp;
}
```



#### 归并排序

>稳定算法
>
>算法思路：分而治之（分治思想），递归分别排序，并且合并两个排序后的数组
>
>时间复杂度：
>
>- 最好、最坏、平均：O(nlogn)
>
>空间复杂度：
>
>- O(n)：需要额外的空间合并数组

```
public int[] sortArray(int[] nums) {
    if(nums.length <= 1){
        return nums;
    }
    
    int num = nums.length / 2;
    int[] left = Arrays.copyOfRange(nums, 0, num);
    int[] right = Arrays.copyOfRange(nums, num, nums.length);

    return merge(sortArray(left), sortArray(right));
}


private int[] merge(int[] left, int[] right){
    int len1 = left.length;
    int len2 = right.length;
    int i = 0, j = 0, k = 0;

    int[] res = new int[len1 + len2];
    while(i < len1 && j < len2){
        if(left[i] < right[j]){
            res[k++] = left[i++];
        }else {
            res[k++] = right[j++];
        }
    }
    while(i < len1){
        res[k++] = left[i++];
    }

    while(j < len2){
        res[k++] = right[j++];
    }

    return res;
}
```







### 缓存淘汰算法

- FIFO（First in First out）：先进先出算法。思路：先进入缓存的，先被淘汰。
- LFU（Least Frequently Used）：最近最常使用。思路：最近使用频率最高的更容易被再次使用。
- LRU（Least Recently User）：最近最少使用。思路：最近被使用的大概率更容易被再次使用。

```
class DLinkNode {
    int key;
    int val;

    DLinkNode prev;
    DLinkNode next;

    public DLinkNode(){}
    public DLinkNode(int key, int val){
        this.key = key;
        this.val = val;
    }
}

int capacity;
DLinkNode dummyHead;
DLinkNode dummyTrail;
Map<Integer, DLinkNode> cache;

public LRUCache(int capacity) {
    this.capacity = capacity;
    dummyHead = new DLinkNode();
    dummyTrail = new DLinkNode();
    cache = new HashMap<>();

    dummyHead.next = dummyTrail;
    dummyTrail.prev = dummyHead;
}

public int get(int key) {
    DLinkNode node = cache.get(key);
    if(node == null){
        return -1;
    }

    removeNode(node);
    addNodeToHead(node);

    return node.val;
}

public void put(int key, int value) {
    DLinkNode node = cache.get(key);
    if(node == null){
        if(cache.size() >= this.capacity){
            DLinkNode rNode = dummyTrail.prev;
            removeNode(rNode);
            cache.remove(rNode.key);
        }
        DLinkNode nNode = new DLinkNode(key, value);
        addNodeToHead(nNode);
        cache.put(key, nNode);
    }else {
        node.val = value;
        removeNode(node);
        addNodeToHead(node);
    }
}

private void removeNode(DLinkNode node){
    node.prev.next = node.next;
    node.next.prev = node.prev;
}

private void addNodeToHead(DLinkNode node){
    node.prev = dummyHead;
    node.next = dummyHead.next;
    node.next.prev = node;
    dummyHead.next = node;
}
```







### 校验算法

完成的数据帧：

![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images/5rmsa7bv09.jpeg)

- 奇偶校验：统计数据中数字1的个数
  - 偶校验位：如果为奇数，则补一个bit1，使得总的1的个数为偶
  - 奇校验位：如果为奇数，则补一个bit0，使得总的1的个数为奇

![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images/v2-9c025c1b6d3b754f46375968fba3f26e_b.jpg)

- 校验和：
  - MD5：一种哈希算法，将任何数据转换成固定长度（128）位数的算法，不可逆。
  - CRC：循环冗余校验，是一种对网络数据包进行多项式计算，并得到固定长度位的数据传输检错算法。



### 其他







## 中间件



### Redis

- 场景：https://www.nowcoder.com/discuss/953289?type=all&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_all_nctrack&gio_id=7A239D7C6F1FE3A8AAC731BCD696C405-1655743167774
- 高频面试题：https://www.nowcoder.com/discuss/945665?type=all&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_all_nctrack&gio_id=7A239D7C6F1FE3A8AAC731BCD696C405-1655743167774



#### Redis用在什么场景？

- 已用：

  - 缓存统计信息、基础用户信息、接口权限信息
  - 幂等性处理（引出Kafka）
    - 四种解决幂等方案：https://juejin.cn/post/6906290538761158670
    - 卡口车辆驶入，会出现重复消费的问题吗？会有的
      - 比如卡口对同一辆车可能会传多份照片
      - Kafka是autocommit机制
        - 如果消费者还没来得及commit就重启，重启后会从kafka拉取未过更新的offset，则会造成重复消费。
        - 如果commit了，但是MQ宕机导致接收不到，则重启后会重复消费
  - bitmap统计设备在线，减少数据库压力
- 其他
  - 简单消息队列
  - 分布式锁



#### Redis应用到了哪些数据结构（缓存）？

- String（缓存统计数据，提高读性能）
- 哈希（服务区的map作为缓存）
- List（卡口基本数据）



### Netty

- 通俗的理解Netty：https://www.zhihu.com/question/24322387
- *Netty知识：https://juejin.cn/post/6844903703183360008
- 面试题：
  - https://www.nowcoder.com/discuss/832208?type=all&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_all_nctrack&gio_id=9B179C1C22CC722DBBC116E475A9AFD2-1656053990442
  - https://juejin.cn/post/6999225355374428168
  - 阿里大牛：https://zhuanlan.zhihu.com/p/148726453



#### 什么是Netty

> Netty是 一个异步事件驱动的网络应用程序框架，用于开发的高性能协议服务器和客户端。Netty本质是上对Java NIO的封装，采用Reactor线程模型（Selector（多路复用）器、Acceptor、Handler）、零拷贝技术，极大的提升了socket通信性能。



#### Netty的特点

> 高并发、传输快和封装好

- **高并发**：Netty 是一款基于 NIO（Nonblocking IO，非阻塞IO）开发的**网络通信框架**，对比于 BIO（Blocking I/O，阻塞IO），他的并发性能得到了很大提高。
- **传输快**：Netty 的传输依赖于零拷贝特性，尽量减少不必要的内存拷贝，实现了更高效率的传输。
- **封装好**：Netty 封装了 NIO 操作的很多细节，提供了易于使用调用接口。



#### Netty的应用场景？你们项目用在什么地方

> Netty主要作为基础通信框架提供高性能、低延时的通信服务。可用于构建高性能、低延时的各种Java中间件，例如阿里分布式服务框架 Dubbo、 RocketMQ 默认使用 Netty 作为通讯框架。

- 作为基础设备通信框架，例如采用NIO做情报板、水电表数据及基础设备信息的采集。
  - 情报板通信：停车位自动发布，其发布过程分为四个阶段，1.删除旧文件 2.创建文件 3.下发文件 4. 播放文
  - 设备状态采集：通过SNMP协议，NIO获取并异步更新设备状态




#### Netty的整个处理流程

![Drawing 1.png](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/imagesCiqc1F-NO9KAUOtaAAE1S5uRlDE275.png)

- 服务端

![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images/166cf93e830044e7%7Etplv-t2oaga2asx-zoom-in-crop-mark%3A3024%3A0%3A0%3A0.awebp)

![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images/166cf9418d4c86e4%7Etplv-t2oaga2asx-zoom-in-crop-mark%3A3024%3A0%3A0%3A0.awebp)



- 客户端

![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images/166cf957e59b5066%7Etplv-t2oaga2asx-zoom-in-crop-mark%3A3024%3A0%3A0%3A0.awebp)



#### NIO、BIO、AIO的区别

- https://juejin.cn/post/6844903687626686472

- 衍生：Linux的五种IO模型的区别（磁盘IO）

![image-20220705103107463](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images/image-20220705103107463.png)

- Java中三种IO模型的区别（BIO、NIO、AIO）

  > Java中的三种IO模型都是依赖操作系统IO进行的封装，

  - BIO：**同步阻塞型IO**（1请求1线程连接），连接建立后用户线程发起IO请求，系统切换到内核态读取磁盘数据到内核缓冲区，此过程中用户线程阻塞等待直到内核缓冲区数据读取完成，再将其复制到用户态缓冲区（再到socket缓冲区）

  - NIO：**同步非阻塞型IO**（多请求1线程连接），连接建立后，用户线程发起IO请求并注册到selector（多路复用器）中，注册完用户线程返回，由Selector（ Selector 其实就是 select/poll/epoll 的外包类）中的线程去检查多路连接的IO是否准备就绪，完毕则调用用户线程将内核缓冲区的数据复制到用户缓冲区。与上面的Linux模型中的普通NIO（不断轮询查看）不同，Java中的NIO是【多路复用IO+信号量IO】，大大减少用户线程的消耗，但是数据从内核到用户的复制仍然由用户线程执行，所以本质上仍然是同步的。

    ![image-20200610173230680](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images/image-20200610173230680.png)

  - AIO：**非同步非阻塞型IO**。与同步型IO不同，内核态到用户态的数据复制在AIO中直接由内核线程负责处理，所以对于用户线程来说，是异步执行的。



#### Netty的线程模型了解吗？

- https://juejin.cn/post/6844903974298976270

>  答：Reactor核心组成部分包括Selector、Acceptor和Handler，其中
>
> - selector 监控连接事件（read/write事件、连接事件）,收到事件后通过**dispatch**进行分发
>
>   - 连接事件：分发到acceptor通过accept接收连接，并创建Handler。
>   - 读写事件：分发到Handler进行处理，**Handler完成read->(decode->compute->encode)->send的业务流程**
>
>   而根据Reactor的数量和工作线程池的数量，又将Reactor分为三种模型。

- 单Reactor单线程模型 （单Reactor单线程）：单线程处理连接事件、读写事件、监听事件等，如果处理Handler出现死循环，将导致整个服务不可用。

![Reactor_1](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images16de9918fe8487b3%7Etplv-t2oaga2asx-zoom-in-crop-mark%3A3024%3A0%3A0%3A0.awebp)

- 单Reactor多线程模型 （单Reactor多线程【处理Handler的线程池】）：业务处理由线程池异步执行，但是在大量高并发的场景下，单Reactor仍然会有性能问题。

![Reactor_2](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images16de9918fc15ffea%7Etplv-t2oaga2asx-zoom-in-crop-mark%3A3024%3A0%3A0%3A0.awebp)

- 主从Reactor多线程模型 （多Reactor多线程) ：主从职责分离，主负责连接建立及验证，从负责事件监听、分发，是目前比较流行的线程模型。

![Reactor_3](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images16de9918fa25729e%7Etplv-t2oaga2asx-zoom-in-crop-mark%3A3024%3A0%3A0%3A0.awebp)

> 主Reactor：通过selector监听连接事件，并调用acceptor创建连接并发送给从Reactor
> 从Reactor：接收到主Reactor的连接后加入队列，通过自己的Selector监听IO管道，并将读写事件分发给Handler的TheadPool，由该线程池做Handler的处理



三种模型详细介绍（挑重点记忆，我面试没遇到过让详细说的。）

- **单线程模型**：所有I/O操作都由一个线程完成，即多路复用、事件分发和处理都 是在一个Reactor线程上完成的。既要接收客户端的连接请求,向服务端发起连 接，又要发送/读取请求或应答/响应消息。一个NIO 线程同时处理成百上千的 链路，性能上无法支撑，速度慢，若线程进入死循环，整个程序不可用，对于高负载、大并发的应用场景不合适。
- **多线程模型**：有一个NIO 线程（Acceptor） 只负责监听服务端，接收客户端的 TCP 连接请求；NIO 线程池负责网络IO 的操作，即消息的读取、解码、编码和 发送；1 个NIO 线程可以同时处理N 条链路，但是1 个链路只对应1 个NIO 线 程，这是为了防止发生并发操作问题。但在并发百万客户端连接或需要安全认证时，一个Acceptor 线程可能会存在性能不足问题。
- **主从多线程模型**：Acceptor 线程用于绑定监听端口，接收客户端连接，将 SocketChannel 从主线程池的Reactor 线程的多路复用器上移除，重新注册到 Sub 线程池的线程上， 用于处理I/O 的读写等操作，从而保证mainReactor只负 责接入认证、握手等操作；



#### EventLoop是什么？和Reactor线程模型的关系

> 答：EventLoop直译即事件轮询，是一种用于事件等待和处理的程序模型。在Netty中，EventLoop可以认为是Reactor 线程模型的事件处理引擎，每个EventLoop都维护一个Selector和TaskQueue，主要负责处理IO事件、普通任务和定时任务。Reactor推荐使用NioEventLoop，其底层基于JDK的Epoll实现，并且避免了JDK Epoll的漏洞。在我的理解上，Reactor、EventLoopGroup、EventLoop、Channel之间的关系如下：
>
> Reactor可以简单的认为是EventLoopGroup，例如主从Reactor即有两个EventLoopGroup。
>
> **EventLoopGroup和EventLoop是一对多**的关系，可以简单理解为线程池和线程的关系，只不过EventLoop有具体的实现，包括轮询（Selector）自己管理的任务队列（TaskQueue），对于从Reactor，其EventLoop的任务队列即Channel队列，轮询监听Channel的IO事件，并调用ChannelPipeline中的Handler进行处理，所以**EventLoop和Channel是一对多的关系**。

![image-20220727105052377](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images/image-20220727105052377.png)



#### TCP 粘包/拆包的原因及解决方法？

> 答：TCP是以流的方式来处理数据，一个完整的包可能会被TCP拆分成多个包进行发送，也可能把小的封装成一个大的数据包发送。

原因：

- 当我们的数据包大于TCP包数据内容空间，则发生拆包，小于则发生粘包。例如：服务端将三个数据包被组装成两个TCP包发送，则服务端发生了粘包，客户端接收到粘包则需要进行拆包处理。

解决：

- FixedLengthFrameDecoder：定长拆包器：应用层协议包简单，数据包长度固定，则可以使用。
- LineBasedFrameDecoder：行拆包器：数据包以换行符作为分隔。
- DelimiterBasedFrameDecoder：自定义分隔符分割器：是行拆分器的通用版本，可以自定义换行符。
- LengthFieldBasedFrameDecoder：基于长度域拆包器：自定义的协议中包含长度域字段，则可以用该拆包器。





#### 什么是零拷贝，跟传统拷贝的区别？

- *https://blog.csdn.net/liyifan687/article/details/106749460
- *https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Netty%20%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90%E4%B8%8E%20RPC%20%E5%AE%9E%E8%B7%B5-%E5%AE%8C/16%20%20IO%20%E5%8A%A0%E9%80%9F%EF%BC%9A%E4%B8%8E%E4%BC%97%E4%B8%8D%E5%90%8C%E7%9A%84%20Netty%20%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%8A%80%E6%9C%AF.md
- *https://www.pdai.tech/md/java/io/java-io-nio-zerocopy.html#%E5%85%B6%E5%AE%83%E7%9A%84%E9%9B%B6%E6%8B%B7%E8%B4%9D%E5%AE%9E%E7%8E%B0
- https://juejin.cn/post/6939881308114354207



**什么是零拷贝**

> 零拷贝是个广义上的概念，可以认为只要能够减少不必要的 CPU 拷贝，都可以理解为是零拷贝。常见的零拷贝优化有以下：
>
> - 操作系统级别的零拷贝
> - 用户态的数据操作优化
>
> DMA： 全称叫直接内存存取（Direct Memory Access），是一种允许外围设备直接访问系统主存的机制。DMA 接管了数据读写的工作，不需要 CPU 再参与 I/O 中断的处理，从而减轻了 CPU 的负担。



**一次传统磁盘IO的过程**

> 磁盘 - 内核 - 用户空间（一次读写时共涉及了4次上下文切换，2次 DMA 拷贝以及2次 CPU 拷贝。）	

![screen-1535441](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images/screen-1535441.png)

- 一次网络IO的过程：web服务区 - 内核 - 用户空间 - 网卡（如果web服务器涉及磁盘IO，则还需要添加磁盘IO过程）![image-20220705102442286](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images/image-20220705102442286.png)



**零拷贝实现**

- **用户态直接IO**：用户空间直接访问硬件设备，通过DMA进行数据传输

![screen-1535947](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images/screen-1535947.png)

- **mmap**：MMAP 是数据不会到达用户空间内存，只会存在于系统空间的内存上，用户空间与系统空间共用同一个缓冲区，两者通过映射关联。（发生了 4 次上下文切换 + 1 次 CPU 拷贝 + 2 次 DMA 拷贝）

![screen-1773287](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images/aHR0cDovL2ltZy5sbGM2ODcudG9wL3VQaWMvc2NyZWVuLTE3NzMyODcucG5n)

- **sendfile**： Linux 2.4 版本开始，减少了内核缓冲区到Socket缓冲区的一次CPU拷贝，采用传输数据描述信息，由网卡DMA直接进行内核缓冲区的数据拷贝。与 mmap 内存映射方式不同的是， sendfile() 调用中数据对用户空间是完全不可见的，可以认为是对nmap的优化。（sendfile再JDK的封装中即`FileChannel#transferTo`方法）

  ![image-20200610154454498](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images/image-20200610154454498.png)



**Netty的零拷贝优化**

> Netty的零拷贝技术除了操作系统级别的功能封装，更多的是面向用户态的数据操作优化。

- **堆外内存**：Netty发送和接收消息主要使用bytebuffer，bytebuffer使用堆外内存，避免 JVM 堆内存到堆外内存的数据拷贝。
- **Composite Buffers**：传统的bytebuffer，如果要合并两个bytebuffer，需要创建一个2*n大小的新数组，再将两个拷贝到新数组中，而Composite Buffers没有真正将多个bytebuffer组合起来，而是保存了他们的引用。
- **FileChannel.transferTo**：Netty底层调用了FileChannel的transferTo方法，该方法即上述的sendfile方式的零拷贝，是操作系统级别的零拷贝技术。



---



### Kafka



Kafka用在什么场景？

- Kafka用于接收情报板、事件检测及其他设备采集的消息，用于与系统服务的解耦，可用做流量控制
- 情报板发送需要保证**有序性**，防止情报板覆盖，采用情报板code作为partitionKey，防止乱序导致的覆盖问题。
- 卡口数据接收需要**防止消息丢失**，采用手动ack机制，保证业务正常后再提交ack。
- Kafka采用最大努力通知配置，BASE理论，柔性事务最终一致性。
  - PCM采用最大努力通知（柔性事务）：消息异步发送，如果没有收到ack，则重复发送，本地重复失败后发送到Exception Queue，由Exception Queue再隔一段时间进行发送，并且会邮件通知相关人员排查。
    - https://juejin.cn/post/7023620718692663326

  - 服务区采用本地消息表：发布情报板后，异步返回发布成功，由于消息可能会丢失（发送端、传输过程等），故采用本地消息表，事务插入发布记录及发布的消息（消息及其状态），如果消息被正常处理后，则返回执行结果修改本地消息表中的发布状态。由于定时任务会定时检测消息状态，如果发布失败，则重新发送。
    - https://juejin.cn/post/6844904041659498509

- Kafka的重复消费问题：幂等性处理
  - https://juejin.cn/post/7002778713943343117
- *Kafka性能、可靠性问题
  - https://juejin.cn/post/7018702635544870948
- Kafka扫盲
  - https://juejin.cn/post/7012815379772768264#heading-3



目前系统可能存在的问题：

1. 如果卡口车辆进入后，业务代码异常，导致消息丢失，如何处理？（车辆实际进去了，但是车位占用数据没有录入，并且卡口消息被消费了）
   1. 开启手动ack机制，业务完成后再ack，防止消息丢失
   2. 重复消费问题：redis幂等处理，数据库唯一键处理
2. 如果前面正常，但是在发布情报板的时候异常，导致消息没发送出去，如何处理？
   1. 采用本地消息表，存储消息状态，防止消息丢失



手动提交ack和本地消息表的区别：

- 手动提交ack主要用于防止业务异常导致消息没有被正常消费的问题，而不能保证消息在传输过程中的其他问题（例如*上游服务宕机导致消息没有被发送、MQ宕机导致消息直接丢失等的问题，MQ可以有副本机制，但是也是最大程度的去避免丢失问题）
  - 服务区应用：卡口车辆通过手动ack，防止业务异常导致消息丢失，进而导致车辆出入卡口数据不能被更新，停车位识别出现问题。
- 本地消息表则可以确保**最终一致性原则**（无论如何都会可以保证数据最终一致），因为其原理是在入口处就保存了请求，例如支付后先通过事务【执行支付业务并插入本地消息表】，然后发送支付消息到MQ，通过定时任务监控本地消息表保证后续业务正常执行（后续业务执行成功后会发MQ做确认），发现还没有完成则重新发送MQ，因此存在重复消费问题，需要对接口做幂等处理。
  - 服务区应用：情报板发布后插入情报板相关业务数据，需要发送情报板更新的消息到另一个服务进行对接更新，如果消息在过程丢失，将会出现情报板已经发布但是没有更新的情况，因此引入本地消息表，事务【执行业务数据+插入本地消息表】，通过定时任务查看该条消息对应的需要更新的业务是否已经完成，没有完成则重新发送。



## Java

### Java并发编程



#### 线程（创建、状态、中断、park/wait/sleep）

1. Java中线程的状态有哪些？

> Java中线程状态有6种，分为是new、runable、blocked、waiting、time-waiting、terminal。

![image-20220706111105500](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images/image-20220706111105500.png)

1. 创建线程的方式有哪些？关闭线程的方法是什么？

> 本质上线程的创建方式只有一种，即new Thread，在此基础上，Java又提供了多种创建线程的方式
>
> - 继承Thread
> - 实现Runnable接口
> - 实现Callable接口
> - 线程池创建
>
> 线程中断：
>
> - https://juejin.cn/post/6844903477894709261
>
> **抢占式中断**：线程提供了stop方式关闭线程，但是该方法被标志为过期方法，不推荐使用，理由是该方法调用后会离地跑出ThreadDeath异常，强制释放该线程持有的资源，如果是在同步代码块中间位置被执行，会导致无法确保数据的安全性（一致性）。
>
> **协作式中断**：正确的关闭线程是用Thead的interrupt方法，JDK开发人员认为终止一个线程的时机应该由线程本身确定，而不是由其他线程决定，所以interrupt方法只是将线程的中断状态标志设置为true，由线程本身去轮询检测该标识，并在合适的时机结束线程。
>
> 有了中断标识后，自然也需要有中断策略，而中断策略可以在JVM层面也可以在Java层做实现，例如JVM将Thread的wait()、sleep()、join()等方法都实现中断标识的轮询操作，避免由于阻塞而线程无法被中断。

2. 守护线程是什么？

> 守护线程即服务于用户线程的线程，**拥有自动结束自己生命周期的特性，而非守护线程不具备这个特点**。通过setDaemon(true)设置。
>
> 例如在主线程中开启新线程打印，主线程结束后，JVM线程仍然不会结束，而是会等待工作线程（子线程）打印完后结束；对于守护线程的打印，如果主线程退出后，JVM线程会直接结束，而不会等待守护线程输出打印结果，即守护线程的优先级是比较低的，没有工作线程的情况下，不会特地等待其打印。
>
> 典型的守护线程如Java种的垃圾回收线程。在JVM中，所有非守护线程都执行完毕后，无论有没有守护线程，虚拟机都会自动推出。

3. 线程、进程和协程的区别
   1. 为什么协程的性能好（GO）

> 两者的本质区别是：是否单独占有内存空间及其他系统资源（如IO）
>
> 1. 本质：进程是系统分配资源的最小单位，线程是CUP调度和执行的最小单位。
> 2. 切换开销：进程的创建和销毁不仅需要保存寄存器和栈信息，还需要资源的分配回收及页调度，开销较大；线程只需要保持栈信息和寄存器，开销较小。
> 3. 稳定性：进程间单独占有内存，即存在内存隔离，而线程是进程的一部分，同个进程内的线程共享进程的内存，所以进程间的崩溃不会相互影响，但是进程内某个线程的崩溃会影响到其他线程。
> 4. 安全性：由于进程间内存相互隔离，所以进程通信比较困难但是访问安全，而线程由于共享同块内存，通信容易，但是在并发下会存在线程安全问题。
>
> 协程：
>
> - 属于线程，其没有上下文的切换的消耗，协程的调度切换是由程序员手动切换的。
> - 原子性操作，由于协程是用户调度的，所以不会出现执行一半的代码片段被强制中断了，因此无需原子操作锁。

4. *线程、进程的中断过程是怎么样的？

- https://mp.weixin.qq.com/s/pKdQu74Sl3PIaKyDlIEExg
- *https://juejin.cn/post/7023773498543702029
- *https://juejin.cn/post/7025201232151052301

> 内中断（异常）：程序执行过程中抛出的异常（处理器及内存以内产生的中断，可以引出线程通过中断关闭）
>
> 外中断：处理器和内存以外的部件引起的中断【IO设备发出的中断、外部信号中断[ESC键]、各种定时器引起的中断】
>
> 时间片中断：保存线程上下文，切换至其他线程进行操作
>
> 
>
> 进程/线程中断过程（时间片中断）：
>
> - 关中断：避免其他高级中断导致现场保存不完整
> - 保存现场和屏蔽字：如程序计数器等
> - 开中断
> - 执行中断服务程序
> - 关中断：执行完中断程序后，关闭中断
> - 恢复现场和屏蔽字：将被中断的程序恢复到原来的状态
> - 开中断，中断返回：中断服务程序的最后一条指令通常是一条中断返回指令，使被中断程序返回到原程序的断点处，以便继续执行任务。

5. 说说Thread.sleep()、Object.wait()、Condition.await()、LockSupport.park()的区别区别（引出线程间状态的变换）

- https://www.pdai.tech/md/java/thread/java-thread-x-lock-LockSupport.html#threadsleep%E5%92%8Cobjectwait%E7%9A%84%E5%8C%BA%E5%88%AB

>Thread.sleep()和Object.wait()的区别：（锁释放、超时时间）
>
>- Thread.sleep()释放CPU，不会释放占有的锁，Object.wait()会释放CPU及占有的锁；
>- Thread.sleep()必须传入时间，Object.wait()可传可不传，不传表示一直阻塞下去；
>- Thread.sleep()到时间了会自动唤醒，然后继续执行；
>- Object.wait()不带时间的，需要另一个线程使用Object.notify()唤醒；
>- Object.wait()带时间的，假如没有被notify，到时间了会自动唤醒，这时又分好两种情况，一是立即获取到了锁，线程自然会继续执行；二是没有立即获取锁，线程进入同步队列等待获取锁；
>
>其实，他们俩最大的区别就是Thread.sleep()不会释放锁资源，Object.wait()会释放锁资源。
>
>
>
>LockSupport核心类：**AQS框架借助于两个类：Unsafe(提供CAS操作)和LockSupport(提供park/unpark操作，底层调用的仍然是Unsafe类)**
>
>Object.wait()和LockSupport.park()的区别：
>
>- 作用域：Object.wait()方法需要在synchronized块中执行，LockSupport.park()可以在任意地方执行；
>
>- 资源释放：Object.wait()释放锁和CPU资源，LockSupport.park()释放CPU不释放锁；
>
>- 中断处理：Object.wait()方法声明抛出了中断异常，调用者需要捕获或者再抛出，LockSupport.park()不需要捕获中断异常；
>
>- 唤醒处理：wait-notify/notifyAll（有顺序要求，notify后需要获取锁，并且notify是随机唤醒的），park-unpark（二元信号量，类似于许可证，无顺序要求，由于不释放锁，所以unpark后立刻执行，unpark可以执行唤醒的线程）
>
>  
>
>Object.wait()和Condition.await()的区别：
>
>两者实现了相同的阻塞功能，不过底层实现不同，Condition.await()底层是先释放锁，然后调用LockSupport.park()来实现阻塞当前线程的。



#### 多线程（线程安全、线程池、线程通信）

1. 怎样理解线程安全？

> 线程安全即当多个线程访问某个对象时，不需要考虑运行环境下的调度、并发，也不需要做额外的同步操作，而调用这个对象的行为都可以得到正确的结果，那么这个对象便是线程安全的。但是在实际的多线程开发中，经常会遇到线程不安全的问题。
>
> 常见的线程安全场景：
>
> - 并发修改共享变量，先读后修改（例如i++）
> - 并发if-then（依赖时序，例如单例）
> - 不同数据间存在绑定关系（例如IP和端口，对于这部分的修改和访问需要保证其原子性，不能修改部分就被访问）

2. *线程的同步方式（线程同步即同个时间某份代码只能有一个线程访问）

>线程安全的方案：
>
>互斥同步（悲观锁）
>
>- Synchronized
>- ReentrantLock
>
>非阻塞同步（乐观锁，避免阻塞和唤醒，内核-用户态的切换而导致的资源消耗，适合竞争不激烈的场景，需要牺牲部分CPU）：
>
>- CAS（比较修改前后的预期值是否一致，不一致则说明被修改，会有ABA问题，所以加入版本-AtomicStampedReference）
>- AtomicInteger、AtomicDouble（JUC包中使用Unsafe类实现CAS）
>
>无同步方案
>
>- 栈封闭（局部变量）
>- 线程本地存储（ThreadLocal）
>- 无状态代码（只提供运算，不提供数据存储）

3. *线程间的如何进行通信？
   - *https://juejin.cn/post/7004401589385609246
   - https://juejin.cn/post/6844904066905014285#heading-9

> - Object.wait-notify/notifyAll：控制两个线程交叉执行，例如A先执行一部分，再执行B，再执行A剩下的部分（lock.wait()）
>
> - LockSupport.park-unpark
>
> - Thread.join：两个线程先后执行
>
> - CountdownLatch：线程D在线程A、B、C执行完后执行（其中ABC同时执行）
>
>   - 创建一个计数器，并设置一个初始值， `CountdownLatch countDownLatch = new CountDownLatch(3)`;
>   - 调用`countDownLatch.await()`进入等待状态，直到计数值变为0；
>   - 在其他线程调用`countDownLatch.countDown()`，该方法会将计数值减一；
>   - 当计数器的值变为 `0` 时，`countDownLatch.await()`等待线程中的方法会继续执行下面的代码。
>
> - CyclicBarrier：线程ABC在准备好后同时执行（即线程间相互等待）。CountdownLatch则适合一等多的场景。
>
>   - 首先创建一个公共对象`CyclicBarrier`，并设置同时等待的线程数，`CyclicBarrier cyclicBarrier = new CyclicBarrier(3);`
>   - 这些线程同时开始准备，准备好后，需要等待别人准备好，所以调用`cyclicBarrier.await()`方法等待别人；
>   - 当指定的需要同时等待的线程都调用了该`cyclicBarrier.await()`方法时，意味着这些线程准备好了，那么这些线程就会开始同时继续执行。
>
> - FutureTask：子线程将结果返回给主线程
>
>   ```
>   Callable<Integer> callable = () -> {
>       System.out.println("子任务开始执行");
>       Thread.sleep(1000);
>       int result = 0;
>       for (int i = 0; i <= 100; i++) {
>       	result += i;
>     	}
>     System.out.println("子任务执行完成并返回结果");
>     return result;
>   };
>   // FutureTask实现了Runnable接口，本质上仍是个runnable
>   FutureTask<Integer> futureTask = new FutureTask<>(callable);
>   new Thread(futureTask).start();
>   // 阻塞主线程
>   Integer result = futureTask.get();
>   ```

4. 多线程开发过吗？通信方式有哪些？

> 多线程开发过，主要是用线程池创新线程，并将任务提交给线程池处理，同时做线程安全相关的处理，比如在Java中Bean默认是单例模式，在多线程下对共享变量进行修改会有线程安全问题，所以需要对其加锁、或者改用线程安全的集合，例如ConcurrentHashMap、CopyOnWriteArrayList、BlockingQueue等。

5. 多线程的理解（why、what、how，引出threadlocal、并发集合、volitile、同步方式（锁））

> 线程是CPU调度和执行的最小单位，多线程的出现本质上是为了充分利用CPU资源，例如多核CPU，多线程可以充分利用多核并行处理，同时为了保证多应用能同时运行，且保证CPU不被例如IO这类操作阻塞导致资源浪费，CPU为线程分配了时间片，当时间片结束后会切换线程，所以多线程间又存在并发情况，而线程的并发操作会导致线程安全问题。Java提供了多种并发类解决线程安全问题，比如锁解决原子性问题（常见的锁包括Synchorize、ReentrantLock，CAS）、volitile解决内存可见性、指令重排问题、threadloca/并发类解决共享变量问题（并发类包括ConcurrentHashMap/HashTable、Vetor/CopyOnWriteArrayList、BlockingQueue等）

5. 多进程(继承什么, 不继承什么)，进程间的通信

> **进程创建**：LInux中通过fork命令进行进程的创建，新进程都是由一个已经存在的进程执行了一个用于创建进程的系统调用而创建的。申请创建新进程的进程是父进程，被创建的进程是子进程。在Unix中，父子进程间形成类似树形的层次结构，进程和其所有子进程形成***进程组***。子进程创建后，父子进程拥有不同的地址空间，即其中一个进程对其地址空间进行了修改，这个修改对其他进程是不可见的。不同进程间的地址空间中的文件的共享通常分为两类：
>
> 1. 不可写的内存区共享
> 2. 可写内存通过写时复制共享：当子线程要对该内存进行修改时，需要复制一份到自己的地址空间中，以确保修改是在自己的私有空间中进行。
>
> **进程状态**：简单状态
>
> ![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/imagese4692f03e7af44d7bb6276acd7a0ab2d%7Etplv-k3u1fbpfcp-zoom-in-crop-mark%3A3024%3A0%3A0%3A0.awebp)
>
> **进程的调度**：
>
> - https://juejin.cn/post/6844903489148026888#heading-3
>
> 操作系统通过PCB（进程控制块）对进程进行调度，PCB包含了进行运行时代状态信息，包括以下三部分：
>
> - 进程标识信息：用户ID、进程ID（PID）、父进程ID
> - 进程状态信息：进程的运行状态
> - 进程控制信息：优先级（获得CPU的优先级）、进程通信信息、资源分配信息
>
> ![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/imagese07287f8a82d700ac8a13b72ed2c5cfe%7Etplv-t2oaga2asx-zoom-in-crop-mark%3A3024%3A0%3A0%3A0.awebp)
>
> **进程通信**：（内存、中间件、文件）：https://baike.baidu.com/item/%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1
>
> - **共享存储**：通过对同块内存进行读写操作
> - **消息通信**：通过***send、recieve***进行发送和接收操作
>   - 直接通信：点对点通信
>   - 间接通信：通过中间媒介（MQ）进行通信
> - **管道通信**：基于文件系统，以FIFO方式进行通信，管道是半双工的，通过系统调用***read(), write()***函数进行读写操作。

7. 线程池

> > ***常见的线程池有哪几种？如果线程池爆了会怎样**？ - ？
>
> - https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Java%20%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2078%20%E8%AE%B2-%E5%AE%8C/12%20%E6%9C%89%E5%93%AA%206%20%E7%A7%8D%E5%B8%B8%E8%A7%81%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%B1%A0%EF%BC%9F%E4%BB%80%E4%B9%88%E6%98%AF%20Java8%20%E7%9A%84%20ForkJoinPool%EF%BC%9F.md
>
> ![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/imagesCgoB5l3kzomAckv5AAAxf6FCPco696.png)
>
> - **FixedThreadPool**：定长线程池，初始数量为0，达到最大数后线程池数量一定并且不会被回收，超过数量的线程则进入等待队列。
>
> - **CachedThreadPool**：可缓存线程池，无线程数量限制（最大可到Integer.MAX），每进来一个任务，如果无空间线程则创建新的线程，等待队列为SynchronousQueue（容量为0），60秒内线程无工作则被回收
>
> - **ScheduledThreadPool**：定时任务线程池，可指定核心线程数量，最大线程数量为Integer.MAX，超过核心数量的线程在执行完后即被回收
>
>   ```java
>   ScheduledExecutorService service = Executors.newScheduledThreadPool(10);
>   
>   // 每十秒定时执行一次
>   service.schedule(new Task(), 10, TimeUnit.SECONDS);
>   
>   // 十秒后，每十秒执行一次
>   service.scheduleAtFixedRate(new Task(), 10, 10, TimeUnit.SECONDS);
>   
>   // 十秒后执行任务，并且在每次任务执行结束后的10秒后再次执行
>   service.scheduleWithFixedDelay(new Task(), 10, 10, TimeUnit.SECONDS);
>   ```
>
> - **SingleThreadExecutor**：单线程线程池。适用于所有被提交的任务都需要被依次执行的场景。
>
> - **SingleThreadScheduledExecutor**：单线程定时线程池。本质和定时线程池一样，只不过底层将线程数设置为1
>
> - **ForkJoinPool**：JDK7后引入的线程池，适合可以产生子任务的任务，例如递归、树的遍历等
>
>   - 特点：除了有任务队列，线程池中的每个线程都有自己的双端队列，任务fork（产生子任务后）会被分配到各个子线程的双端队列中，如果某个线程执行任务繁重，并且有其他线程空闲，则会用“work-stealing” 算法，从队列另外一端获取任务进行执行。
>
>   ![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/imagesCgotOV3kzomAflZxAAB99x9-MzI241.png)
>
>   ![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/imagesCgoB5l3nFSOAFOkbAABvJKvhTKk938.png)
>
> 
>
> >**实现线程池，你觉得核心是什么**
>
> - 线程数量的管理（核心/最大线程数量）
> - 线程等待队列（当任务>核心线程数量时如何处理）
> - 拒绝策略（队列已满并且线程达到最大线程数量时如何处理）
>
> 
>
> > **线程池及参数，maximumSize 怎么达到**；（线程池拒绝策略、核心线程等原理）
>
> ![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/imagesimagesCgoB5l3eH8mAAoJCAACEOKMHtpw036.png)
>
> 
>
> > **线程池等拒绝策略**
>
> - AbortPolicy：直接抛出异常，开发者可以感知任务失败并捕获异常，做相关的处理
> - DiscardPolicy：直接丢掉，消息会无感知丢失，存在数据丢失风险
> - DiscardOldestPolicy：丢弃队列头部的任务（通常是在队列中待的时间最久的），同样存在数据丢失风险
> - CallerRunsPolicy：由提交的线程执行其提交的任务（比较完善）。有以下好处：
>   - 由提交任务的线程执行，数据不会丢失
>   - 提交任务的线程执行任务，即被占用，不能再提交，减缓任务提交的速度，为线程池提供缓冲期处理
>
> ![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/imagesimagesCgotOV3g0WWAVWVlAAEsBI6lEEA162.png)
>
> 
>
> > **线程池的等待队列**
>
> ![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/imagesCgq2xl3nUryAJBkpAAA0_WFSrB8184.png)
>
> 
>
> > **线程池的处理过程**
>
> - 核心线程满则放入队列 -> 队列满则启动备用策略，创建非核心线程 -> 达到最大数量则采用拒绝策略
>
> ![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/imagesimagesCgoB5l3eH-KAAHpkAAC4vEMOXQ4797.png)
>
> 
>
> > **线程池相关工具类介绍**
>
> JUC中的Executors.new线程池()，相关的类包括
>
> - ThreadFactory（默认创建非守护线程）
> - 等待队列
> - 拒绝策略（RejectedExecutionHandler）



#### 线程同步（Synchorized、Lock） 

1. **Java有哪些锁，分别适用于哪些场景**

> 从待线程同步时实现思想的不同，可以分为：
>
> - 乐观锁：乐观锁认为使用数据时不会有别的线程修改，所以不会加锁，只记录更新前后的数据等值判断是否被修改，如果被其他线程修改了，则根据不同的实现执行不同的操作，例如抛出异常或者自动重试（通常是后者）。Java中JUC的Atomic类都是基于CAS实现乐观锁。
> - 悲观锁：悲观锁认为在修改数据时一定会有其他线程来修改，所以在修改前会先加锁，确保不会被其他线程修改。Java中的Synchronized和Lock都是基于悲观锁思想实现。
>
> 从Synchronized去看待锁的轻重程度，可以分为：
>
> - 偏向锁
> - 轻量级锁
> - 重量级锁
>
> 从线程申请锁时获取锁的顺序，可以分为：
>
> - 公平锁：新线程来的时候如果等待队列不为空，会进入等待队列。例如ReentrantLock的公平模式。
> - 非公平锁：新线程来的时候，无论等待队列是否为空，都会先做锁抢占，成功则执行，失败则入队。例如Synchorize，则为非公平模式。
>
> 从同个线程是否可以重复获取锁，可以分为：
>
> - 可重入锁：当线程递归调用的时候，获取同个锁时会将锁计数+1而不是阻塞，在一定程度上可以避免死锁。ReentrantLock和synchronized都是可重入锁。
> - 不可重入锁：同个线程获取多次获取同个锁，第二次会进入阻塞状态。
>
> 从锁是否可以被多个线程同时持有人，可以分为：
>
> - 共享锁（读锁）：当某个线程对数据加了读锁后，其他线程仍然可以加读锁，但是不能加写锁。例如ReentrantReadWriteLock，本质上是实现了两个锁ReadLock和WriteLock（底层都是AQS的Sync实现），读锁可以保证并发读性能高效，而读写、写读、写写的过程互斥。公平模式下，阻塞队列的线程依次去做锁的获取；非公平模式下，写锁可以一直参与到锁的抢占，避免出现写锁饥饿的情况。
> - 独享锁（排他锁/写锁）：当某个线程对数据加了写锁后，该线程独占数据，不能被其他线程修改和读取。例如ReentrantLock。

2. **synchronized**
   - https://pi-ka-chu.github.io/2019/12/synchronize%E5%85%B3%E9%94%AE%E5%AD%97/
   - *https://juejin.cn/post/6844903918653145102#heading-15

> > **锁（synchronized 和 Lock），synchronized 加到普通方法和静态方法的区别，一个类的两个方法都加了 synchronized，是一个锁还是两个锁**； - ？
>
> 答：synchronized可以修饰方法、代码块，加的锁分为类锁和对象锁，例如synchronized修饰static和普通方法，修饰static的加的是**类锁**，不同对象对该方法的调用，都会出现锁竞争的情况，并且只有一个对象可以获取到锁。对于普通方法，加的是**对象锁**，即当前对象，即同时调用时只能有一个方法被调用，因为是对象锁，不同对象之间的调用则不会相互阻塞。
>
> 
>
> > **synchronized的方法同步和代码块同步区别**
>
> - *synchronized加锁原理：https://juejin.cn/post/6844903918653145102
>
> 答：两者在JVM的底层实现是不同的
>
> - 同步代码块的实现主要基于对象监视器（Monitor）实现，其主要是利用`monitorenter`和`monitorexit`指令实现代码同步。
> - 同步方法则是依靠方法修饰符上的`ACC_SYNCHRONIZED`标识实现同步。被synchronized修饰的方法上会有ACC_SYNCHRONIZED标识，有该标识的方法需要先获取monitor对象锁，默认是当前对象，而同步代码块可以指定加锁的对象，通常我们是定义一个final对象，防止对象被修改导致无法达到锁的效果。
>
> 
>
> > **synchronized的原理**
>
> 第一层（synchronized）：synchronized可以修饰方法和代码块，同步代码块底层采用Monitor对象的minitorenter和monitorexit指令进行加锁和解锁。同步方法底层是对方法加了ACC_SYNCHRONIZED标识，而有该标识的方法需要先获取Monitor对象锁，所以本质上synchronized通过Monitor对象进行加锁解锁操作。
>
> 第二层（Monitor）：Monitor又称为监视器，其实现了在一个时间点，最多只有一个线程在执行监视器的某个子程序，工作原理如下：
>
> - 想要获取monitor的线程,首先会进入_EntryList队列。
> - 当某个线程获取到对象的monitor后,进入_Owner区域，设置为当前线程,同时计数器_count加1。
> - 如果线程调用了wait()方法，则会进入_WaitSet队列。它会释放monitor锁，即将_owner赋值为null,_count自减1,进入_WaitSet队列阻塞等待。
> - 如果其他线程调用 notify() / notifyAll() ，会唤醒_WaitSet中的某个线程，该线程再次尝试获取monitor锁，成功即进入_Owner区域。
> - 同步方法执行完毕了，线程退出临界区，会将monitor的owner设为null，并释放监视锁。
>
> ![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images16ca34f7e0149c3d%7Etplv-t2oaga2asx-zoom-in-crop-mark%3A3024%3A0%3A0%3A0.awebp)
>
> 第三层（Minitor和对象的关联）：
>
> 由图可知道，Monitor对象通过对象的Mark Work中的互斥量指针进行关联（重量级锁的情况下），所以在重量级锁的情况下，线程在获取锁的时候会去Monitor对象中做锁的获取。
>
> ![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images16ca45741a93cf93%7Etplv-t2oaga2asx-zoom-in-crop-mark%3A3024%3A0%3A0%3A0.awebp)
>
> 不同锁的加锁过程（锁的膨胀）：
>
> - 偏向锁：
>   1. 访问`Mark Work`中偏向锁的标识是否为1（默认为1，即开启状态）
>   2. 如果为可偏向状态，则检查`_owner`线程Id是否指向当前线程，如果是，进入步骤5，否则进入步骤3
>   3. 如果线程ID未指向当前线程，则通过`CAS`操作竞争锁。如果加锁成功（成功加锁后获取锁的线程再次进入时只需校验是否当前获取锁的线程Id，无需再进行CAS操作），则执行步骤5；如果加锁失败，则执行步骤4。
>   4. 如果`CAS`获取偏向锁失败，则表示当前存在竞争，在到达全局安全点时，获取到偏向锁的线程被挂起，**偏向锁升级为轻量级锁**，然后被阻塞在安全点的线程继续执行同步代码。
>   5. 执行同步代码。
>   6. **释放锁**：偏向锁不会由线程主动释放，而是等到其他竞争锁的线程出现时，暂停拥有偏向锁的线程，检查线程是否存活，如果不存活，则恢复到无锁状态，允许其他线程竞争；如果存活，则挂起持有偏向锁的线程，将对象头`Mark word`修改为指向锁记录指针的标识，**锁升级为轻量级锁状态（00）**，最后重新唤醒挂起的线程。
> - 轻量级锁：（轻量级获取锁的依据是第四步的栈帧和Mark Word相互指向成功，这个替换过程由CAS进行操作，如果执行过程中Mark Work中的指针发现变化，则说明有其他线程获取到了锁，此时线程继续自旋直到轻量级锁被释放，即Mark Work中的Lock Record被赋值回来，如果一直失败，则在一定次数后膨胀到重量级锁）
>   1. 在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁标识为“0”），虚拟机首先将在**当前线程的栈帧**中建立一个名为**锁记录**（`Lock Record`）的空间，用于存储锁对象目前的`Mark Word`的拷贝，官方称之为`Displaced Mark Word`。
>      ![image.png](http://ww1.sinaimg.cn/mw690/0061iV1igy1ga0yp11ok4j30t00dqtd3.jpg)
>   2. 拷贝对象头中的`Mark Word`复制到锁记录中。
>   3. 拷贝成功后，虚拟机将使用`CAS`操作尝试将对象的`Mark Word`更新为指向`Lock Record`的指针，并将`Lock record`里的`owner`指针指向`object mark word`。如果更新成功，则执行步骤4，否则执行步骤5。
>   4. 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象`Mark Word`的锁标志位设置为“00”，即表示此对象处于**轻量级锁定状态**，这时候线程堆栈与对象头的状态如下图所示。
>      ![image.png](http://ww1.sinaimg.cn/mw690/0061iV1igy1ga0yurrfbqj30sa0iyag8.jpg)
>   5. 如果这个更新操作失败了，虚拟机首先会检查对象的`Mark Word`是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁（**重入**，每次获取轻量级锁时都会创建一个 `Lock Record`，锁重入时会创建多个指向同一个`Object`的`Lock Record`，除第一次设置`Displaced Mark Word` ，后面均设置为 null），那就可以直接进入同步块继续执行。否则说明**多个线程竞争锁**，（多次自旋无果后）轻量级锁就要**膨胀为重量级锁**，锁标志的状态值变为“10”，`Mark Word`中存储的就是指向重量级锁（互斥量)的指针，后面等待锁的线程也要进入**阻塞状态**。 而当前线程便尝试使用自旋来获取锁，自旋就是为了不让线程阻塞，而采用循环去获取锁的过程。
>   6. **释放锁**：利用`CAS`操作把当前线程的栈帧中的`Displaced Mark Word`替换回锁对象的`Mark Word`中去，如果替换成功，则解锁成功，恢复到无锁的状态（01）。若替换失败，则轻量级锁膨胀为重量级锁后再解锁。
> - 重量级锁
>   - 重量级锁即为第二层的Monitor对象加锁过程，其应用到操作系统的互斥量进行操作，涉及到用户态和内核态的切换，开销比较大。
>
> 
>
> 总结：
>
> ![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images16ca4f292061cb0a%7Etplv-t2oaga2asx-zoom-in-crop-mark%3A3024%3A0%3A0%3A0.awebp)
>
> 
>
> **synchronized的优化**：
>
> - **锁膨胀**：1.7后，synchronized采用了锁膨胀的优化，如偏向锁、轻量级锁、重量级锁
>
> - **锁消除**：单线程下采用并发类或加锁，则锁会被消除
>
>   > 例如StringBuffer是一个线程安全的类，其内部方法使用Synchronize修饰，但是如果我们是在单线程下使用StringBuffer进行字符串操作，那么不存在线程安全问题（线程封闭），但是频繁的加锁和解锁会造成性能消耗，此时Java在运行时会把锁消除进行优化（运行时优化，javap无法查看），可以利用工具查看Java最终运行的汇编代码，利用汇编指令表可以对照查看。
>
> - **锁粗化**：
>
>   > 例如在for循环中循环的加锁，会频繁的进行加锁解锁操作，造成性能消耗，Java会进行优化，将锁范围进行扩大，例如扩到到for循环外部。
>
> - **自旋锁**：
>
>   > 轻量级锁加锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。
>
>   

2. **JUC**
   - https://juejin.cn/post/6844903601534418958
   - *https://juejin.cn/post/6844903601538596877

> > **JUC包的目录结构**
>
> ![concurrent目录结构.png](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images163260cff7a637f5%7Etplv-t2oaga2asx-zoom-in-crop-mark%3A3024%3A0%3A0%3A0.awebp)
>
> > **JUC包的整体实现图**
>
> ![concurrent包实现整体示意图.png](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images163260cff7cb847c%7Etplv-t2oaga2asx-zoom-in-crop-mark%3A3024%3A0%3A0%3A0.awebp)
>
> 
>
> > **说一说ReentrantLock**
>
> ReentrantLock是可重入锁（排他锁），提供了公平和非公平两种模式。与Synchorized不同，ReentrantLock是在Java层面实现，其底层通过实现Lock接口，并用AQS的实现类Sync做加锁、解锁和线程同步等操作。ReentrantLock本身没有太多代码，其核心代码都有Sync属性做了实现和操作，而Sync继承自AQS，所以AQS是ReentrantLock实现的核心组件。
>
> 
>
> > **说一说AQS**
>
> AQS即抽象队列同步器，其采用了模版方法的设计模式，封装了底层同步状态管理、线程排队、等待和唤醒等底层操作。并提供了抽象方法给具体类实现，如独占式获取与释放锁、共享式获取与释放锁，例如ReentrantLock提供了公平和非公平锁两种模式，底层就是通过继承AQS实现了两个锁，并且在tryAcquire（锁的获取）做不同的实现（true则抢占锁成功，false则失败），公平的返回false（AQS封装了入队操作），非公平的直接抢占，成功则返回true（AQS认为其加锁成功）。总的来说AQS的主要包括以下过程：
>
> 1. 线程调用**acquire**方法尝试加锁(CAS改变同步状态state以及设置当前线程为owner线程)
> 2. 成功则执行业务代码，失败则调用**addWaiter**方法将线程封装成Node节点，通过CAS加入等待队列
>    - AQS的等待队列是一个**Node节点组成的双端队列**，有虚拟头部和尾指针
> 3. 当锁的拥有者执行完业务释放锁后，调用**acquireQueue**方法获取等待队列头部Node（非虚拟head），调用unpark唤醒并调用acquire进行加锁操作
>    1. （等待队列中的锁获取过程是FIFO）
> 4. 成功则获取锁并执行业务，失败则调用park阻塞该节点
>
> ![独占式锁获取（acquire()方法）流程图.png](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/images163261637c891cc2%7Etplv-t2oaga2asx-zoom-in-crop-mark%3A3024%3A0%3A0%3A0.awebp)

3. CAS：

> > **ABA问题如何解决**
>
> CAS即compare and swap，其实现逻辑即：在修改某内存值前，将该值跟预期值做比较，如果相等（说明期间没有其他线程进行修改），则进行修改操作，否则取消操作。而如果当纯用值做比较，则可能会出现ABA的问题，即在修改过程中，内存值被修改为A，然后又被修改成B，这导致跟我们的预期值一致，但实际是经过了并发修改，为了解决这个问题，引入了版本号，每次修改该变量，则版本号加一。
>
> Java中的CAS操作是由Unsafe类提供的compareAndSwapXXX方法操作，是个原子性操作，底层是一条 CPU 的原子指令（cmpxchg指令），该命令加了内存屏障，保证其执行的原子性及锁住内存。我的理解：
>
> - 操作前记录内存值
> - 执行业务操作，准备好要修改的新值
> - 通过CAS原子性操作（通过内存屏障锁内存，保证CAS只有一个执行，而不会有两个CAS并发执行）
>
> ```
> int prev, next;
> do {
>   prev = get();
> 	next = updateFunction.applyAsInt(prev);
> } while (!compareAndSet(prev, next));
> ```
>
> 



#### 并发类（ThreadLocal、Volitile、原子类）

1. ThreadLocal 用过吗？底层如何实现的？作用是什么？应用场景？ *  2
   - *https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Java%20%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2078%20%E8%AE%B2-%E5%AE%8C/44%20ThreadLocal%20%E9%80%82%E5%90%88%E7%94%A8%E5%9C%A8%E5%93%AA%E4%BA%9B%E5%AE%9E%E9%99%85%E7%94%9F%E4%BA%A7%E7%9A%84%E5%9C%BA%E6%99%AF%E4%B8%AD%EF%BC%9F.md

> **项目应用**：
>
> 用过，ThreadLocal我们用来保存每个请求的用户基本信息，ThreadLocal相当于为每个线程创建了副本变量，每个线程获取到的都是自己的用户数据，这样我们只需在网关解析用户信息并保存到ThreadLocal中，在线程经过的方法如果需要用到用户信息，则直接从ThreadLocal获取即可。
>
> **底层实现**：
>
> ThreaLocal是用来解决线程安全问题的，但是它解决的不是多线程的资源共享问题，而是换了一种思路，为每个线程创建变量副本，所以对于本身就希望多线程间数据共享的场景，ThreadLocal并不适用，这时可以用Synchorized，当然Synchorized也可以解决ThreaLocal的场景一的问题，但是加锁并发性能大大降低，ThreadLocal则可以牺牲一定的内存，提高并发性能。
>
> - Thread、TreadLocal、ThreadLocalMap三者的关系：ThreadLocalMap是Thread的一个属性，即1对1的关系，而ThreadLocal的引用则作为ThreadLocalMap的key，set的值则作为ThreadLocalMap的value。
> - ThreadLocalMap本质上是一个Entry 类型的数组，可以理解为类似HashMap的Key，Value结构，和HashMap采用拉链法解决哈希冲突不同，ThreadLocalMap采用的是线性探测法解决，即继续往下找下一个空位。
> - 获取ThreadLocal中value的流程如下
>   - 通过threadLocal的get方法获取
>   - get方法中会获取当前线程并获取线程的ThreadLocalMap（Entry数组）中的Entry
>   - 接着从Entry获取该值并返回
>
> ![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/imagesCgq2xl5M5a6ADeCKAABC52ZxZCk238.png)
>
> 
>
> **应用场景**：
>
> 1. **保证线程安全**：**每个线程有各自的副本对象，将原本并发线程不安全的情况变成*线程安全*的情况**。例如：线程池 + SimpleDateFormat（线程不安全）+ ThreadLocal（加了ThreadLocal则安全，因为每个线程获取到的都是各自的副本）
> 2. **单线程中优雅的共享变量**：**每个线程都有自己的副本对象，并且可以方便的共享给其他方法**。例如：用户信息保存到ThreadLocal中，在需要的时候直接获取，而不需要通过参数传递。
>
> 
>
> **ThreadLocal如何解决内存泄漏问题**
>
> ThreadLocal的内存泄漏主要是ThreadLocalMap的key（ThreadLocal）和value（T），当线程执行完之后，ThreadLocal中的信息已经没有用了，并且方法栈中ThreadLocal的引用也消除了，但是仍然被线程的ThreadLocalMap引用，这会导致GC做可达性分析时标志为可达，造成内存泄漏，为了解决这个问题，JDK开发者做了以下措施：
>
> 1. Key对ThreadLocal的引用采用虚引用，所以当线程执行完业务后，虚引用的Key可以被GC。并且在执行 ThreadLocal 的 set、remove、rehash 等方法时，会扫描key为null的entry，将其value值置为null，以保证value值可以被GC。
> 2. 但是还是会有问题，假设ThreadLocal不再被使用，并且线程又一直存活，那么value还是会有内存泄漏问题，所以为了保证其可以被正常回收，在使用完ThreadLocal后，会调用其remove方法将value值删除。
>
> ![img](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/imagesCgq2xl5Pld-AHFhJAADLtGXmSxc833.png)

2. 用过原子类吗？答AtomicInteger，问它的原理；

> AtomicInteger是JUC的Atomic包下的类，可以在多线程并发的情况下对其进行计算操作，底层采用乐观锁实现，即volitile+CAS去更新value 值，其中volitile保证了value在多线程下的可见性，CAS保证了其并发修改的安全性。

3. 说说volitile（引出单例）

> volitile是Java中用于解决线程安全问题的类，可以认为是轻量版的synchorized，volitile只解决多线程下的可见性及指令重排带来的安全性问题，而不解决原子性问题。
>
> - **可见性**：可见性问题出现的原因是由于CPU和主存的运行速度相差太大，为了提升CPU的使用率，在其两者间加入了了缓存，线程对值的修改都会先写入缓存，再写入内存中，单线程下是没有问题的，但是如果多线程下，而CPU又拥有多核，那么不同线程修改的值都更新在各自都CPU核对应的缓存上，导致出现可见性问题，volitile解决的就是这个问题，被volitile修饰的变量的修改会被直接更新到主存，读取也是从主从中读取，这样即解决了多线程下的可见性问题。
> - **指令重排**：以普通懒汉式单例模式为例子，当我们获取单例时，会先检查该对象是否为空，不为空就返回，单线程下是没问题的，但是多线程并发操作下，返回的实例可能由于指令重排还没被实例化，进而导致出错。通常创建实例的流程是这样的：类加载 - 获取类元信息 - 申请内存 - 根据类元信息创建实例 - 返回内存地址到方法栈，但是指令重排可能导致在申请内存后直接返回地址，然后才是创建实例，而如果返回到地址被其他线程调用，则会出现对象不为空但是还没实例好导致出错。

4. 并发集合（引出集合类）

> ![image](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/imagesjava-thread-x-juc-overview-2.png)
>
> **CopyOnWriteArrayList**
>
> 原理：底层采用反射 + ReentrantLock保证线程安全问题
>
> - 读不加锁
> - 写加锁（可重入锁），复制新数组，往新数组写入新元素，将数组引用指向复制的数组
>
> 使用场景：读多写少，且数据量不大的场景
>
> 缺点：
>
> - 性能问题：由于写操作的时候，需要拷贝数组，会消耗内存，如果原数组的内容比较多的情况下，可能导致young gc或者full gc（大对象创建）
> - 一致性问题：不能用于实时读的场景，像拷贝数组、新增元素都需要时间，所以调用一个set操作后，读取到数据可能还是旧的,虽然CopyOnWriteArrayList 能做到最终一致性,但是还是没法满足实时性要求；
>
> 
>
> **ConcurrentHashMap**
>
> 本质：ConcurrentHashMap是一个线程安全的Map集合
>
> - 存储结构上：
>   - 1.7：数组 + 链表
>   - 1.8：数组 + 链表 + 红黑树（超过8转换为红黑树，红黑树空间为Node的两倍，但是查询效率更高，为log(n)）
> - 线程安全上：
>   - 1.7：**Segment分段锁**保证线程安全，相比较HashTable直接对整个对象加锁，segment降低了锁的粒度，提高了并发性能，segment继承自ReentrantLock，本质上是一把悲观锁。segment的数量默认是16，并且初始化后即使扩容也不能改变。
>   - 1.8：采用 **Volatile + CAS + synchronized**保证线程安全，当目标Node数组的元素为空时，采用CAS去对Node数组做值的更新，当目标Node数组不为空，并且Key不同，即发生了哈希冲突，则采用synchorized锁住Node，并且做冲突处理。
>
> 主体结构：
>
> - Node节点
>
>   ```
>   static class Node<K,V> implements Map.Entry<K,V> {
>   
>       final int hash;
>   
>       final K key;
>   
>       volatile V val;
>   	
>   		// 哈希冲突时的链表
>       volatile Node<K,V> next;
>   
>       // ...
>   }
>   ```
>
> - put方法
>
>   - 计算key的哈希值
>   - 检查当前的Node数组是否为空，如果为空则进行初始化（默认为16）
>   - 初始化后根据哈希值计算数组下标（（n-1）& hash）
>     - 如果当前下标的Node为空则通过CAS方式放入新值；
>       - 如果当前槽点有数据，则比较key
>         - 相同则通过CAS覆盖值。
>         - 不相同则说明出现哈希冲突，通过synchronized锁住当前Node节点，判断当前的哈希冲突数据机构
>           - 如果为链表则遍历链表，找到相同key则覆盖，没找到则添加，并检查添加后长度是否超过8，超过则将链表转换为红黑树
>           - 如果为红黑树结构，则调用putTreeVal往树中添加元素
>
> - get方法
>
> 
>
> **LinkedBlockingQueue**
>
> - LinkedBlockingQueue实现了BlockingQueue接口，底层采用链表对元素进行存储，可以设置链表长度，默认为Integer.MAX_VAL，其采用FIFO的方式进行元素出队，并且采用ReentrantLock进行加锁处理，保证并发安全。像定长线程池和单线程线程池都采用LinkedBlockingQueue作为其阻塞队列。
>
> - BlockingQueue：BlockingQueue是一个阻塞队列接口，定义了四组不同的方法用于插入和移除队列元素（put和take为阻塞的，其他失败都会返回或者抛异常），常用与作为生产者和消费者之间的等待队列，生产者将任务put入队列，消费者从另外一端take出。
>
>   ![image-20220711003303473](https://raw.githubusercontent.com/PI-KA-CHU/Image-OSS/main/imagesimage-20220711003303473.png)
>
> 
>
> **SynchronousQueue**
>
> - 用于可缓存线程池，队列容量为0，只提供阻塞作用，当任务来时阻塞直到线程池take。



### JVM

- **对象从产生到消亡的过程**（类加载、内存分配、对象创建、代码运行、GC（垃圾标识、垃圾回收）



GC：

- Minor gc 、Major gc和full gc的区别
- 堆内存的垃圾回收算法（引出垃圾标识算法、垃圾回收器）
- Full GC场景
- 说一下GC
- GC机制



JVM调优

- 有过调优经验吗



JMM

- 描述一下Java内存模型
  - JVM操作栈
  - 本地方法栈
  - 程序计数器
  - 堆
  - 元方法区（引出类加载过程）
- Java的内存分配过程
- HotSpot 中的持久代指的是哪个分区？
- 堆的分区是怎样的？（引出对象从young区到old区到整个过程，接着引出GC）
- Java堆栈的区别
- *什么情况下会发生OOM？（除了代码问题外，可以引出GC问题）
  - 遇到过内存泄漏问题吗？

类加载机制

- 关于JVM 类加载器机制








## 我要问的

1. 请问是外包吗？
2. 请问一共有几轮面试？多久会有结果通知？
3. 请问部门做的项目主要是什么类型的





## 面试题

### CVTE

- https://www.nowcoder.com/discuss/917826?type=all&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_all_nctrack&gio_id=9B179C1C22CC722DBBC116E475A9AFD2-1654668824810
- https://www.nowcoder.com/discuss/857854?type=all&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_all_nctrack&gio_id=9B179C1C22CC722DBBC116E475A9AFD2-1654668824810
- https://www.nowcoder.com/discuss/917826?type=post&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_post_nctrack
- https://www.nowcoder.com/discuss/827803?type=post&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_post_nctrack
- https://www.nowcoder.com/discuss/786302?type=post&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_post_nctrack
- https://www.nowcoder.com/discuss/779334?type=post&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_post_nctrack
- https://www.nowcoder.com/discuss/627151?type=post&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_post_nctrack



### 金山

- WPS：https://www.nowcoder.com/discuss/experience/company?tagId=1046
  - https://www.nowcoder.com/discuss/73974
  - https://www.nowcoder.com/discuss/659778?source_id=&channel=
  - https://www.nowcoder.com/discuss/657896?source_id=&channel=
  - https://www.nowcoder.com/discuss/635511?source_id=&channel=
  - https://www.nowcoder.com/discuss/634811?source_id=&channel=
  - https://www.nowcoder.com/discuss/584694?source_id=&channel=
  - https://www.nowcoder.com/discuss/546327?source_id=&channel=
  - https://www.nowcoder.com/discuss/540803?source_id=&channel=
  - https://www.nowcoder.com/discuss/797239?source_id=&channel=

- 金山云：https://www.nowcoder.com/discuss/experience/company?tagId=1003
  - https://www.nowcoder.com/discuss/98899?source_id=&channel=
  - https://www.nowcoder.com/discuss/94884?source_id=&channel=
  - https://www.nowcoder.com/discuss/93663?source_id=&channel=



### 牛客网其他

- *https://www.nowcoder.com/discuss/855750?source_id=profile_create_nctrack&

