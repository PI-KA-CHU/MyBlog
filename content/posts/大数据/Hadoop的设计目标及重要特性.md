 +++
author = "pikachu"
title = "Hadoop的设计目标及重要特性"
date = "2019-03-13"
description = "Lorem Ipsum Dolor Si Amet"
draft = false
tags = [
    "大数据"
]
categories = [
    "IT"
]
+++

 
# 一、Hadoop 2.x的相关组件：
 
**HDFS（Hadop分布式文件系统）：负责分布式数据存储**

- NameNode：存储元信息，包括文件块的分块数量及文件块的储存位置
- DataNode：管理文件块的存储
- SeconddaryNameNode：

**YARN：负责资源管理，即任务调度**

- ResourceManager
- NodeManager

**MapReduce：离线计算框架，负责数据的运算**

**HDFS和YARN逻辑上分离，但物力物理上总是在一起。**

&nbsp;
 
# 二、hadoop的相关配置文件：

- **default.xml**（可在官网查看）：这配置了hadoop默认的配置选项，如果用户没有更改，那么里面的选项将会生效。
- **site.xml**：配置了用户需求自定义的配置选项
- **区别**：site中的配置选项优先级大于default中的，如果有配置的话会覆盖默认的配置选项。

&nbsp;

# 三、关于HDFS的格式化：
- 首次启动hdfs的时候需要进行格式化
- 格式化的本质是机进行文本系统的初始化操作，创建一些自己所需要的配置文件
- 格式化后，若集群启动成功，则后续不要再进行格式化操作，否则可能导致对应不上标识而导致集群创建失败

&nbsp;

# 四、HDFS的创建思路
- （大数据存储）**传统文件的存储模式缺点**：
    - 上传下载速度慢（文件太大）
    - 遇到存储瓶颈，即使进行纵向扩展（扩充磁盘和内存），也会存在极限
- **HDFS的解决思路**：
    - 将文件进行分割切块，将大文件分割成小块进行分布式上传存储
    - 进行横向扩展，添加集群机器进行处理
- **HDFS解决传统模式后出现的问题及解决**：
    - **获取文件的成本变高**：切块存储后，需要一个**记录文件切割以及保存在哪里的相应信息**的数据。
    - **单点故障**：某一机器的故障将导致无法切块的文件无法复原。
        - **解决**：将文件进行**备份存储**，在多个机器上备份文件块，在其中一台机器挂掉后，可以到另外机器获取

&nbsp;

# 五、HDFS的重要特性

- **HDFS的本质**：
    - 是一个**文件系统**，同于存储文件，通过统一的命名空间目录树来定位文件。
    - 是**分布式**的，由很多服务器联合起来是实现其功能。
    
- **master / slave架构**：
    - 一个HDFS集群是由一个Namenode和一定数目的Datanode组成。`Namenone是HDFS集群主节点，Datanode是HDFS集群从节点`，两者共同协调完成分布式的文件存储服务。

- **分块存储**：
    - HDFS中的文件在物理上是分块存储（block）的，块的大小可以通过配置参数来规定，hadoop2.x中默认大小是128M.

- **名字空间（NameSpace）**：
    - HDFS支持传统的**层次型文件组织结构**，用户或者应用程序可以创建目录，然后将文件保存在这些目录里，即用户可以创建、删除、移动和重命名文件。
    - **Namenode**负责**维护文件系统的名字空间**，任何对文件系统名字空间或属性的修改都将被Namenode记录下来。
    - HDFS会给客户端提供一个统一的**抽象目录树**，客户端通过路径来访问文件，如"hdfs://namenode:port/etc/host.conf"

- **Namenode元数据管理**：
    - **元数据**：目录结构及文件分块位置信息
    - Namenode负责维护整个hdfs文件系统的**目录树结构**及每一个文件所对应的**block块信息**（block的id及所在的datanode服务器）

- **Datanode数据存储**：
    - 文件的各个**block的具体存储管理**由datanode节点承担，每个block都可以在多个datanode上。
    - Datanode需要定时向Namenode汇报自己的block信息。
    - 存储多个副本（副本数量可以通过设置参数`dfs.replication`,默认是3）

- **副本机制**：
    - 为了**容错**，防止单点故障带来的问题，**文本的所有block都会有副本**。每个**block的大小**和**副本系数**都是可配置的。应用程序可以指定某个文件的副本数目，副本系统可以在文件创建的时候指定，也可以在之后改变。

- **一次写入，多次读出**
    - HDFS是设计成适应**一次写入，多次读出**的场景，且不支持文件的修改。
    - 因为此特性，HDFS适合用来做**数据分析的底层存储服务**，并不适用用于做网盘等应用（修改不方便，延迟大，网络开销大，成本太高）